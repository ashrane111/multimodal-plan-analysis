import sys
import os

# --- PATH PATCH START ---
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)
# --- PATH PATCH END ---

import torch
import numpy as np
from transformers import Trainer, TrainingArguments, LayoutLMv3Processor
import evaluate 

from src.data.dataset import FloorPlanDataset
from src.models.layoutlm_v3 import LayoutLMv3Model

# We wrap the metric function to give it access to the label map (id2label)
def get_compute_metrics(id2label):
    def compute_metrics(p):
        metric = evaluate.load("seqeval")
        predictions, labels = p
        predictions = np.argmax(predictions, axis=2)

        # Remove ignored index (special tokens) AND convert ints to string labels
        true_predictions = [
            [id2label[p] for (p, l) in zip(prediction, label) if l != -100]
            for prediction, label in zip(predictions, labels)
        ]
        true_labels = [
            [id2label[l] for (p, l) in zip(prediction, label) if l != -100]
            for prediction, label in zip(predictions, labels)
        ]

        results = metric.compute(predictions=true_predictions, references=true_labels)
        return {
            "precision": results["overall_precision"],
            "recall": results["overall_recall"],
            "f1": results["overall_f1"],
            "accuracy": results["overall_accuracy"],
        }
    return compute_metrics

def main():
    # 1. Setup Processor
    processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)

    # 2. Initialize Dataset
    full_dataset = FloorPlanDataset(
        parsed_csv_path="data/processed/parsed_layout.csv",
        image_dir="data/raw",
        processor=processor
    )
    
    # 3. Initialize Model
    labels = full_dataset.labels
    # Get the mapping from the dataset (e.g. {0: 'LivingRoom', 1: 'Kitchen'})
    id2label = full_dataset.id2label 
    label2id = full_dataset.label2id
    
    model_wrapper = LayoutLMv3Model(
        num_labels=len(labels),
        id2label=id2label,
        label2id=label2id
    )
    
    # 4. Training Arguments
    training_args = TrainingArguments(
        output_dir="models_output/checkpoints",
        max_steps=20,
        per_device_train_batch_size=2,
        per_device_eval_batch_size=2,
        learning_rate=5e-5,
        eval_strategy="steps",
        eval_steps=10,
        save_steps=10,
        logging_steps=5,
        remove_unused_columns=False,
        report_to="none"
    )

    # 5. Trainer
    trainer = Trainer(
        model=model_wrapper.model,
        args=training_args,
        train_dataset=full_dataset,
        eval_dataset=full_dataset,
        # Pass the function generated by our helper
        compute_metrics=get_compute_metrics(id2label), 
    )

    print("Starting Training...")
    trainer.train()
    
    # 6. Save Final Model
    final_path = "models_output/layoutlmv3_finetuned"
    trainer.save_model(final_path)
    processor.save_pretrained(final_path)
    print(f"Model saved to {final_path}")

if __name__ == "__main__":
    main()